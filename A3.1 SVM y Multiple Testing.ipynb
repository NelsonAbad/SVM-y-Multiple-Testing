{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5b1e4c-6960-4d92-9ff4-20e042301b7b",
   "metadata": {},
   "source": [
    "Importamos los datos de la base de datos de `Khan`, esta es una base de datos donde se vienen 83 muestras y 2308 variables que consisten en la expresión génica estandarizada de distintos genes. La variable de salida cuenta con valores numéricos del 1 al 4 que\n",
    "corresponden a distintos tipos de cáncer, o sea, una clase. Antes de empezar a trabajar con este dataframe revisamos que no tenga huecos, a lo que no se encuentra ninguno. Posteriormente, buscamos comparar las clases 2 y 4, por lo que asignamos la salida a cada grupo como grupo2 como aquellas cuya salida Y sea 2 y grupo4 para cuyas salidas Y sea 4. Despues, tomamos todos los valores dentro de una variable cuyas observaciones hayan tenido como salida 2 y lo promediamos, a continuacion hacemos lo mismo para salidas de 4. Despues el promedio para cada variable, buscamos la diferencia entre las que tenian como salida 2 y 4 para luego enlistar las 10 de diferencia mas grande. Estas diferencias podrian ayudar a distinguir entre los tipos de cáncer y de manera que a mayor diferencia, se podria interpretar que \"el comportamiento del gen varia dependiendo del tipo de cancer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688b8a90-3bd9-40a8-9580-1dcaa5a80a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna:\n",
      "0\n",
      "\n",
      "X187     3.323151\n",
      "X509     2.906537\n",
      "X2046    2.424515\n",
      "X2050    2.401783\n",
      "X129     2.165185\n",
      "X1645    2.065460\n",
      "X1319    2.045941\n",
      "X1955    2.037340\n",
      "X1003    2.011337\n",
      "y        2.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"A3.1 Khan.csv\")\n",
    "\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print()\n",
    "\n",
    "grupo2 = df[df[\"y\"] == 2]\n",
    "grupo4 = df[df[\"y\"] == 4]\n",
    "\n",
    "diferencia = (grupo2.mean(numeric_only=True) - grupo4.mean(numeric_only=True)).abs()\n",
    "\n",
    "top10 = diferencia.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(top10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c53e03ee-425e-4148-b50c-6326ac913ca1",
   "metadata": {},
   "source": [
    "En este análisis, se calcularon pruebas t para comparar las medias de expresión de cada gen entre las clases 2 y 4.\n",
    "Sin embargo, dado que se realizaron más de dos mil comparaciones (una por cada gen), existe una alta probabilidad de encontrar falsos positivo, o sea, genes que parecen diferir entre clases solo por azar. Por esta razón, aplicamos diferentes métodos de corrección por comparaciones múltiples, que ajustan los valores p para mantener control sobre los errores estadísticos.\n",
    "\n",
    "Método de Bonferroni:\n",
    "Este método controla el error familiar (FWER), es decir, la probabilidad de cometer al menos un error tipo I en todas las pruebas. Se logra dividiendo el nivel de significancia α entre el número total de pruebas (m), o multiplicando cada p-value por m. En la práctica, esto hace que el criterio para rechazar una hipótesis sea mucho más estricto \n",
    "$$\n",
    "p_i < \\frac{\\alpha}{m}\n",
    "$$\n",
    "por lo que rara vez se declara algo como significativo. En nuestro contexto, Bonferroni reduce casi completamente los falsos positivos, pero también puede eliminar genes que realmente sí difieren entre clases.\n",
    "\n",
    "Método de Holm-Bonferroni:\n",
    "El método de Holm es una versión más flexible de Bonferroni, ya que el umbral de rechazo depende de la posición ordenada de cada p-value. Primero se ordenan los valores p de menor a mayor, y luego se compara cada uno con un límite \n",
    "$$\n",
    "p_{(j)} < \\frac{\\alpha}{m + 1 - j}\n",
    "$$ \n",
    "donde j es su posición en la lista. Esto significa que los p-values más pequeños tienen un umbral más estricto, y los más grandes, más flexible.\n",
    "\n",
    "Método de Benjamini-Hochberg (FDR):\n",
    "Finalmente, el método de Benjamini-Hochberg no controla el FWER, sino la tasa de falsos descubrimientos (FDR).\n",
    "En lugar de intentar evitar cualquier falso positivo, tolera que exista un pequeño porcentaje de ellos, pero asegura que su proporción sea baja.\n",
    "Esto lo hace ideal para estudios genómicos como este, donde se analizan miles de genes. El método ordena los p-values y los compara con umbrales proporcionales a su posición\n",
    "$$\n",
    "p_{(j)} < \\frac{q \\times j}{m}\n",
    "$$\n",
    "garantizando que, por ejemplo, si el FDR se fija en 0.05, no más del 5% de los genes detectados como significativos son falsos positivos en promedio. Por ello, Benjamini-Hochberg suele ser el método más apropiado en análisis de expresión génica masiva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "987a48a0-b1db-4f08-ad4e-e281e063acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonferroni: 72 genes significativos\n",
      "Holm: 72 genes significativos\n",
      "Benjamini-Hochberg: 296 genes significativos\n",
      "\n",
      "Genes significativos con Bonferroni:\n",
      "       Gen    t_stat       p_value    p_bonf    p_holm          p_bh  sig_bonf  \\\n",
      "1      X2 -6.900138  7.383962e-08  0.000170  0.000168  5.497479e-06      True   \n",
      "35    X36  5.610781  7.885432e-07  0.001820  0.001786  4.136268e-05      True   \n",
      "66    X67 -4.793322  1.413077e-05  0.032614  0.031681  4.867735e-04      True   \n",
      "128  X129 -8.412602  2.516574e-09  0.000006  0.000006  2.904126e-07      True   \n",
      "173  X174 -6.974367  5.603441e-09  0.000013  0.000013  6.158448e-07      True   \n",
      "\n",
      "     sig_holm  sig_bh  \n",
      "1        True    True  \n",
      "35       True    True  \n",
      "66       True    True  \n",
      "128      True    True  \n",
      "173      True    True  \n",
      "\n",
      "Genes significativos con Holm:\n",
      "       Gen    t_stat       p_value    p_bonf    p_holm          p_bh  sig_bonf  \\\n",
      "1      X2 -6.900138  7.383962e-08  0.000170  0.000168  5.497479e-06      True   \n",
      "35    X36  5.610781  7.885432e-07  0.001820  0.001786  4.136268e-05      True   \n",
      "66    X67 -4.793322  1.413077e-05  0.032614  0.031681  4.867735e-04      True   \n",
      "128  X129 -8.412602  2.516574e-09  0.000006  0.000006  2.904126e-07      True   \n",
      "173  X174 -6.974367  5.603441e-09  0.000013  0.000013  6.158448e-07      True   \n",
      "\n",
      "     sig_holm  sig_bh  \n",
      "1        True    True  \n",
      "35       True    True  \n",
      "66       True    True  \n",
      "128      True    True  \n",
      "173      True    True  \n",
      "\n",
      "Genes significativos con Benjamini-Hochberg:\n",
      "     Gen    t_stat       p_value    p_bonf    p_holm      p_bh  sig_bonf  \\\n",
      "1    X2 -6.900138  7.383962e-08  0.000170  0.000168  0.000005      True   \n",
      "2    X3  4.255350  9.621623e-05  0.222067  0.213119  0.002343     False   \n",
      "28  X29  3.452663  1.113505e-03  1.000000  1.000000  0.014121     False   \n",
      "35  X36  5.610781  7.885432e-07  0.001820  0.001786  0.000041      True   \n",
      "51  X52  3.802063  4.065804e-04  0.938387  0.879433  0.006427     False   \n",
      "\n",
      "    sig_holm  sig_bh  \n",
      "1       True    True  \n",
      "2      False    True  \n",
      "28     False    True  \n",
      "35      True    True  \n",
      "51     False    True  \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "genes = [col for col in df.columns if col != \"y\"]\n",
    "t_stats = []\n",
    "p_values = []\n",
    "\n",
    "for gen in genes:\n",
    "    t, p = ttest_ind(grupo2[gen], grupo4[gen], equal_var=False) \n",
    "    t_stats.append(t)\n",
    "    p_values.append(p)\n",
    "\n",
    "resultados = pd.DataFrame({\n",
    "    \"Gen\": genes,\n",
    "    \"t_stat\": t_stats,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "# Bonferroni\n",
    "resultados[\"p_bonf\"] = multipletests(resultados[\"p_value\"], method='bonferroni')[1]\n",
    "# Holm\n",
    "resultados[\"p_holm\"] = multipletests(resultados[\"p_value\"], method='holm')[1]\n",
    "# Benjamini-Hochberg (FDR)\n",
    "resultados[\"p_bh\"] = multipletests(resultados[\"p_value\"], method='fdr_bh')[1]\n",
    "\n",
    "#significativos (α = 0.05)\n",
    "resultados[\"sig_bonf\"] = resultados[\"p_bonf\"] < 0.05\n",
    "resultados[\"sig_holm\"] = resultados[\"p_holm\"] < 0.05\n",
    "resultados[\"sig_bh\"] = resultados[\"p_bh\"] < 0.05\n",
    "\n",
    "signif_bonf = resultados[resultados[\"sig_bonf\"]]\n",
    "signif_holm = resultados[resultados[\"sig_holm\"]]\n",
    "signif_bh = resultados[resultados[\"sig_bh\"]]\n",
    "\n",
    "print(\"Bonferroni:\", len(signif_bonf), \"genes significativos\")\n",
    "print(\"Holm:\", len(signif_holm), \"genes significativos\")\n",
    "print(\"Benjamini-Hochberg:\", len(signif_bh), \"genes significativos\")\n",
    "\n",
    "print(\"\\nGenes significativos con Bonferroni:\\n\", signif_bonf.head())\n",
    "print(\"\\nGenes significativos con Holm:\\n\", signif_holm.head())\n",
    "print(\"\\nGenes significativos con Benjamini-Hochberg:\\n\", signif_bh.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27737c4-7e37-4f7c-a24f-224bd976e90d",
   "metadata": {},
   "source": [
    "Para hacer la comparativa, ahora se realizó un análisis de varianza (ANOVA) para comparar las medias de expresión génica entre las cuatro clases de cáncer presentes en la base de datos Khan. El ANOVA evalúa si las diferencias entre los promedios de las clases son estadísticamente significativas. Un valor p bajo (< 0.05) indica que al menos una clase presenta una expresión distinta para ese gen. Tras aplicar la corrección por múltiples comparaciones mediante el método de Benjamini-Hochberg, se identificaron los genes cuya expresión difiere significativamente entre las cuatro clases. Estos genes son los que más probablemente participen en los mecanismos biológicos que distinguen los distintos tipos de cáncer, y podrían representar marcadores potenciales para estudios posteriores de clasificación o inferencia biológica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a3fb04c-7c76-4b22-b5b2-89b8018383ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de genes con diferencias significativas entre las 4 clases: 1162\n",
      "        Gen     F_stat       p_value          p_bh  significativo\n",
      "1954  X1955  84.364086  1.459035e-24  2.045755e-21           True\n",
      "1388  X1389  83.817537  1.772751e-24  2.045755e-21           True\n",
      "1002  X1003  77.795622  1.618988e-23  1.245542e-20           True\n",
      "2049  X2050  69.230799  4.733702e-22  2.731346e-19           True\n",
      "245    X246  68.414042  6.633722e-22  3.062126e-19           True\n",
      "741    X742  65.572797  2.195548e-21  8.445542e-19           True\n",
      "0        X1  59.118264  3.839240e-20  1.265852e-17           True\n",
      "2161  X2162  56.987623  1.035143e-19  2.986387e-17           True\n",
      "1953  X1954  55.419914  2.182635e-19  5.597246e-17           True\n",
      "186    X187  54.615724  3.217900e-19  6.751740e-17           True\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# clases\n",
    "grupo1 = df[df[\"y\"] == 1]\n",
    "grupo2 = df[df[\"y\"] == 2]\n",
    "grupo3 = df[df[\"y\"] == 3]\n",
    "grupo4 = df[df[\"y\"] == 4]\n",
    "\n",
    "#ANOVA\n",
    "genes = [col for col in df.columns if col != \"y\"]\n",
    "f_stats = []\n",
    "p_values = []\n",
    "\n",
    "for gen in genes:\n",
    "    f, p = f_oneway(grupo1[gen], grupo2[gen], grupo3[gen], grupo4[gen])\n",
    "    f_stats.append(f)\n",
    "    p_values.append(p)\n",
    "\n",
    "resultados_anova = pd.DataFrame({\n",
    "    \"Gen\": genes,\n",
    "    \"F_stat\": f_stats,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "#FDR Benjamini-Hochberg\n",
    "resultados_anova[\"p_bh\"] = multipletests(resultados_anova[\"p_value\"], method='fdr_bh')[1]\n",
    "resultados_anova[\"significativo\"] = resultados_anova[\"p_bh\"] < 0.05\n",
    "\n",
    "signif_anova = resultados_anova[resultados_anova[\"significativo\"]]\n",
    "print(\"Número de genes con diferencias significativas entre las 4 clases:\", len(signif_anova))\n",
    "print(signif_anova.sort_values(\"p_bh\").head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ac510-588b-4dbe-9ff1-a80ef8b52fc3",
   "metadata": {},
   "source": [
    "Se separaron los datos en conjuntos de entrenamiento (70%) y prueba (30%).\n",
    "A partir de los genes con mayor diferencia de expresión entre clases, se entrenaron tres modelos de Máquinas de Vectores de Soporte (SVM) con distintos tipos de kernel: lineal, polinomial de grado 3 y radial.\n",
    "\n",
    "Aunque la selección de variables se realizó con base en el análisis previo (usando todos los datos), esto implica una fuga de datos, ya que la información del conjunto de prueba influyó indirectamente en la elección de características. En un análisis riguroso, la selección de genes debería realizarse solo con los datos de entrenamiento, pero por esta ocacion se pasara por alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52e0c464-1458-4f0c-9065-2b4e6bdb0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# genes dados por el AVOVA\n",
    "genes_seleccionados = [\n",
    "    \"X1955\", \"X1389\", \"X1003\", \"X2050\", \"X246\",\n",
    "    \"X742\", \"X1\", \"X2162\", \"X1954\", \"X187\"\n",
    "]\n",
    "\n",
    "X = df[genes_seleccionados]\n",
    "y = df[\"y\"]\n",
    "\n",
    "# train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# entrenar SVM \n",
    "svm_lineal = SVC(kernel='linear', random_state=42)\n",
    "svm_poly = SVC(kernel='poly', degree=3, random_state=42)\n",
    "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "svm_lineal.fit(X_train, y_train)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "modelos = {\n",
    "    \"Lineal\": svm_lineal,\n",
    "    \"Polinomial (grado 3)\": svm_poly,\n",
    "    \"Radial (RBF)\": svm_rbf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b4c374-eb58-4414-8089-3f31adf0ac02",
   "metadata": {},
   "source": [
    "Después de entrenar los tres modelos SVM (lineal, polinomial y radial), se calcularon distintas métricas de desempeño con el fin de comparar su rendimiento.\n",
    "Para ello, se utilizaron las funciones accuracy_score, precision_score, recall_score, f1_score y confusion_matrix de la librería scikit-learn.\n",
    "\n",
    "El código recorre los tres modelos almacenados en el diccionario modelos, genera las predicciones correspondientes (y_pred) sobre el conjunto de prueba y calcula las métricas principales:\n",
    "Exactitud (accuracy): mide la proporción total de aciertos del modelo.\n",
    "Precisión: indica qué proporción de las predicciones positivas fueron correctas.\n",
    "Recall (sensibilidad): muestra qué proporción de los casos reales fueron detectados correctamente.\n",
    "F1-Score: representa el equilibrio entre la precisión y el recall, útil para evaluar modelos con clases desbalanceadas.\n",
    "\n",
    "Se utiliza el parámetro average='weighted' para que las métricas se calculen considerando el tamaño (support) de cada clase.\n",
    "Los resultados se almacenan en una lista de diccionarios y se convierten en un DataFrame (tabla_resultados) para visualizar de manera comparativa el desempeño de los tres modelos.\n",
    "\n",
    "Finalmente, se imprime la matriz de confusión de cada modelo. Esta matriz permite observar el número de aciertos y errores por clase, identificando qué clases son más difíciles de distinguir, ademas de que al estar trabajando con todas las clases (1, 2, 3, 4) se espera verificar cuales de las salidas son desplegadas correctamente y cuales fueron predichas incorrectamente. La forma en la que esta acomodada es en orden ascendente, desde 1 hasta 4 de izquierda a derecha siendo lo predicho y de 1 a 4 de arriba a abajo siendo esto lo el dato real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c1e46f0-6cfa-4f57-8041-1c9fd68ba9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Modelo  Exactitud  Precisión  Recall  F1-Score\n",
      "0                Lineal       0.92   0.930000    0.92  0.921524\n",
      "1  Polinomial (grado 3)       0.88   0.912727    0.88  0.878297\n",
      "2          Radial (RBF)       0.96   0.964000    0.96  0.959719\n",
      "\n",
      "Matriz de confusión - Lineal\n",
      "[[3 0 0 0]\n",
      " [1 8 0 0]\n",
      " [0 0 5 0]\n",
      " [0 1 0 7]]\n",
      "\n",
      "Matriz de confusión - Polinomial (grado 3)\n",
      "[[3 0 0 0]\n",
      " [0 8 0 1]\n",
      " [0 0 3 2]\n",
      " [0 0 0 8]]\n",
      "\n",
      "Matriz de confusión - Radial (RBF)\n",
      "[[3 0 0 0]\n",
      " [0 9 0 0]\n",
      " [0 0 5 0]\n",
      " [0 1 0 7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "metricas = []\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    metricas.append({\n",
    "        \"Modelo\": nombre,\n",
    "        \"Exactitud\": acc,\n",
    "        \"Precisión\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1\n",
    "    })\n",
    "\n",
    "tabla_resultados = pd.DataFrame(metricas)\n",
    "print(tabla_resultados)\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nMatriz de confusión - {nombre}\")\n",
    "    print(confusion_matrix(y_test, modelo.predict(X_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
